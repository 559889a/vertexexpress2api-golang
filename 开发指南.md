# vertex2api-golang 开发指南（架构说明）

本指南面向后续接手的 LLM，解释如何从零实现一个仅基于 Vertex Express API Key 的轻量代理，提供 OpenAI 兼容接口与 Gemini 原生接口，支持多 key 轮询与错误重试，覆盖文本/图片、生图、流式与工具调用。平台需兼容 Windows / Linux / Termux，避免重型依赖。

## 范围与目标
- 认证：只支持 Vertex Express API Key，多 key 轮询或随机；不涉及 SA/JSON、HuggingFace、广播。
- 接口：`/v1/chat/completions`、`/v1/models`（OpenAI 兼容）；`/gemini/v1beta/*`（Gemini 原生）；`/health`。
- 功能：文本/图片混合输入，工具调用（function_call）、流式与非流式输出，生图；提供 Gemini 3 Pro 高/低思考别名模型。
- 可靠性：无熔断，错误时按配置次数与间隔重试，可切换 key。

## 目录与分层建议
```
cmd/server/main.go          # 启动、路由注册
internal/config/config.go   # 环境变量解析、默认值
internal/auth/middleware.go # API_KEY 鉴权
internal/keys/express.go    # Express key 管理，随机/轮询 + 重试调度
internal/models/models.go   # 请求/响应结构体，模型别名（含 gemini-3-pro-preview-high/low）
internal/vertex/client.go   # Vertex REST 封装（generateContent/streamGenerateContent）
internal/translate/oai.go   # OpenAI -> Gemini prompt 转换（文本、图片、工具）
internal/translate/stream.go# reasoning 标签拆分、SSE 输出
internal/handlers/oai.go    # /v1/chat/completions, /v1/models
internal/handlers/gemini.go # /gemini/v1beta/*
internal/health/health.go
```

## 环境变量
| 变量 | 说明 |
| --- | --- |
| `APP_PORT` | 监听端口 |
| `API_KEY` | 代理层鉴权（必填） |
| `VERTEX_EXPRESS_API_KEY` | 逗号分隔的 Express key 列表，轮询/随机使用 |
| `GCP_PROJECT_ID` | 明确项目 ID，缺省则自动发现并缓存 |
| `GCP_LOCATION` | 地区，默认 `global` |
| `ROUNDROBIN` | 是否轮询 key（false 为随机） |
| `RETRY_MAX` | 每次请求的最大重试次数（默认 3，可自定） |
| `RETRY_INTERVAL_MS` | 重试间隔毫秒（默认 1000） |
| `MODELS_CONFIG_URL` | 远程模型列表 URL，空则用本地或默认 |
| `PROXY_URL` / `SSL_CERT_FILE` | 代理与自签证书 |
| `SAFETY_SCORE` | 是否在响应中附加安全分数 |

## 关键设计
1) Express Key 选择与重试  
   - 维护 key slice + mutex；根据 `ROUNDROBIN` 轮询或随机取 key。  
   - 每个请求：按 `RETRY_MAX` 和 `RETRY_INTERVAL_MS` 重试；失败可换下一个 key；不做熔断。  
   - `PickAuth()` 返回 (projectId, apiKey, location)；记录 key 索引用于日志。

2) Project ID 发现  
   - 优先使用 `GCP_PROJECT_ID`。  
   - 缺省时对某 key 发送故意错误请求，从报错中解析 projectId，缓存映射 `apiKey -> projectId`。

3) 模型与别名  
   - 启动时尝试加载 `vertexModels.json`（本地或 `MODELS_CONFIG_URL`），失败则使用内置默认列表。  
   - 别名：`gemini-3-pro-preview-high` / `gemini-3-pro-preview-low`，在调用前注入 thinking_level（高/低）。

4) OpenAI 兼容 `/v1/chat/completions`  
   - 支持 messages/tools/tool_choice/n/logprobs 等；可选保留 `-openai`/`-openaisearch` 直连 OpenAI（按需）。  
   - Prompt 转换：system 合并为 system_instruction；角色 user/assistant/tool -> user/model/function。  
   - 图片：识别 `image_url.url` data URL 和 Markdown base64，转为 inline bytes，保持顺序。  
   - 工具：assistant.tool_calls -> function_call；tool -> function_response。  
   - 生成配置映射：temperature/top_p/top_k/max_output_tokens/stop/candidate_count(seed) 等；`SAFETY_SCORE` 时附加安全分数。  
   - 调用：`generateContent` / `streamGenerateContent`，URL `publishers/google/models/{model}`，参数带 `key`，支持代理/TLS。  
   - 流式：SSE `data: ...` + `[DONE]`；用状态机拆 `<vertex_think_tag>`，分离 reasoning_content 与 content。

5) Gemini 原生 `/gemini/v1beta/*`  
   - 路由：`models/{model}:generateContent`、`:streamGenerateContent`。  
   - 鉴权：`API_KEY`；也接受 URL `key` / header `x-goog-api-key` / Bearer。  
   - 调用复用 Express key 选择与重试策略。

6) `/v1/models`  
   - 返回模型列表 + 别名，字段遵循 OpenAI 风格（id/object/created/owned_by/root/parent）。

7) 日志与监控  
   - 结构化日志：request id、model、key index、latency、retry 次数、HTTP 状态、错误信息。  
   - 可选接入 metrics（请求量、失败率、平均延时）以便后续扩展。

## 实施步骤（推荐顺序）
1. 配置解析、日志骨架、`/health`。  
2. Express key 选择与重试调度、projectId 发现缓存。  
3. 模型加载/缓存 + `/v1/models`。  
4. Prompt 转换 + `/v1/chat/completions` 非流式。  
5. 流式/SSE + reasoning 拆分；工具调用与图片处理。  
6. Gemini 原生路由。  
7. 重试策略微调、代理与证书、性能与内存优化。

## 跨平台与性能注意
- 避免 CGO 与平台特定特性；路径用 `filepath`；不依赖 systemd/inotify。  
- 复用 `http.Client`，设置合理超时；SSE 时及时 flush，避免大对象拷贝；大 base64 可限制请求大小。  
- 保持响应字段与 OpenAI 兼容（id/object/choices/usage），便于现有客户端直接使用。
